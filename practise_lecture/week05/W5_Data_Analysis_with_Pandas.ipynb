{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RtcCxotjxhL"
      },
      "source": [
        "#What is Pandas?\n",
        "Pandas is a Python library used for working with data sets.\n",
        "\n",
        "It has functions for analyzing, cleaning, exploring, and manipulating data.\n",
        "\n",
        "The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\" and was created by Wes McKinney in 2008.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdmgvGxdkZv9"
      },
      "source": [
        "#Why Use Pandas?\n",
        "Pandas allows us to analyze big data and make conclusions based on statistical theories.\n",
        "\n",
        "Pandas can clean messy data sets, and make them readable and relevant.\n",
        "\n",
        "Relevant data is very important in data science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLVOI-CRkbqk"
      },
      "source": [
        "#What Can Pandas Do?\n",
        "Pandas gives you answers about the data. Like:\n",
        "\n",
        "Is there a correlation between two or more columns?\n",
        "- What is average value?\n",
        "- Max value?\n",
        "- Min value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5VhMt8HkoHm"
      },
      "source": [
        "#Getting started\n",
        "\n",
        "###Installation of Pandas\n",
        "```\n",
        "pip install pandas\n",
        "```\n",
        "###Import Pandas\n",
        "```\n",
        "import pandas\n",
        "```\n",
        "```\n",
        "import pandas as pd\n",
        "```\n",
        "###Checking Pandas Version\n",
        "```\n",
        "import pandas as pd\n",
        "\n",
        "print(pd.__version__)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2nMGA7D3jZlP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    cars  passings\n",
            "0    BMW         3\n",
            "1  Volvo         7\n",
            "2   Ford         2\n"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "import pandas as pd\n",
        "\n",
        "mydataset = {\n",
        "  'cars': [\"BMW\", \"Volvo\", \"Ford\"],\n",
        "  'passings': [3, 7, 2]\n",
        "}\n",
        "\n",
        "myvar = pd.DataFrame(mydataset)\n",
        "\n",
        "print(myvar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SoUH_fhmBDr"
      },
      "source": [
        "#Panda Data Structure\n",
        "\n",
        "Let's first get acquainted with two of pandas' primary data\n",
        "structures: the **Series** and the **DataFrame**. They can handle\n",
        "the majority of use cases in *finance*, *statistic*, *social science*,\n",
        "and many areas of engineering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNw4p9o5mXJv"
      },
      "source": [
        "###SERIES\n",
        "A Series is a one-dimensional object similar to an array, list,\n",
        "or column in table. Each item in a Series is assigned to an\n",
        "entry in an index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRdPWy-wmdHL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "a = [1, 7, 2]\n",
        "\n",
        "myvar = pd.Series(a)\n",
        "\n",
        "print(myvar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Ik1p-7nFss"
      },
      "outputs": [],
      "source": [
        "# Create labels\n",
        "import pandas as pd\n",
        "\n",
        "a = [1, 7, 2]\n",
        "\n",
        "myvar = pd.Series(a, index = [\"x\", \"y\", \"z\"])\n",
        "print(myvar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQfpQxfzmpGc"
      },
      "source": [
        "Exercises:\n",
        "1. Creating a Series data structure of 5 random values.\n",
        "2. Adding labels (i, j, x, y, z) to that Series.\n",
        "3. Print out the first value (column \\\"i\\\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    4\n",
            "1    4\n",
            "2    2\n",
            "3    2\n",
            "4    2\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Solution\n",
        "import random\n",
        "\n",
        "\n",
        "data = pd.Series(random.choices(range(1,5), k=5))\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8XJ2PH-oL56"
      },
      "source": [
        "###Key/Value Objects as Series\n",
        "Create a simple Pandas Series from a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEg8nMDjqZVD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
        "\n",
        "myvar = pd.Series(calories)\n",
        "\n",
        "print(myvar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eChZ3sIPqcPC"
      },
      "outputs": [],
      "source": [
        "#Create a Series using only data from \"day1\" and \"day2\":\n",
        "\n",
        "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
        "\n",
        "myvar = pd.Series(calories, index = [\"day1\", \"day2\"])\n",
        "\n",
        "print(myvar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwdMSvzmq0l9"
      },
      "source": [
        "###Data Frames\n",
        "- The DataFrame is a tabular data structure comprising a set\n",
        "of ordered columns and rows.\n",
        "- It can be thought of as a group of Series objects that share\n",
        "an index (the column names). There are a number of ways\n",
        "to initialize a DataFrame object.\n",
        "- Firstly, let's take a look at the common example of creating\n",
        "DataFrame from a dictionary of lists:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQi1wRv2rk6s"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "  \"calories\": [420, 380, 390],\n",
        "  \"duration\": [50, 40, 45]\n",
        "}\n",
        "\n",
        "myvar = pd.DataFrame(data)\n",
        "\n",
        "print(myvar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNbaUA_HteDD"
      },
      "outputs": [],
      "source": [
        "#Locate Row\n",
        "print(myvar.loc[0,\"calories\"])\n",
        "print(myvar.loc[[0, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyvjEZoetluK"
      },
      "outputs": [],
      "source": [
        "#Loate index\n",
        "print(myvar.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nsn_eZsbCB7"
      },
      "source": [
        "###Read CSV Files\n",
        "\n",
        "A simple way to store big data sets is to use CSV files (comma separated files).\n",
        "\n",
        "CSV files contains plain text and is a well know format that can be read by everyone including Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEPGawT3bWJ6"
      },
      "outputs": [],
      "source": [
        "#Load the CSV into a DataFrame:\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nExwMMxwge8y"
      },
      "outputs": [],
      "source": [
        "# max_rows and max_columns\n",
        "print(pd.options.display.max_rows)\n",
        "print(pd.options.display.max_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtq6tR9eg-Jr"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_rows = 9999\n",
        "pd.options.display.max_columns = 4\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3fMG6n1hVdm"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', 7)\n",
        "pd.set_option('display.max_rows', 5)\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYQdJJ35ht9D"
      },
      "source": [
        "###Read json\n",
        "\n",
        "Big data sets are often stored, or extracted as JSON.\n",
        "\n",
        "JSON is plain text, but has the format of an object, and is well known in the world of programming, including Pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcsKHuhTh_uB"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json('data.json')\n",
        "\n",
        "print(df.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6ynGT-LijaN"
      },
      "source": [
        "#Analyzing DataFrames\n",
        "### Viewing the Data\n",
        "using head(), tail(), describe(), columns...\n",
        "\n",
        "\n",
        "> using titanic.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HHA42WTjY06"
      },
      "outputs": [],
      "source": [
        "# Describe features\n",
        "# We can use .describe() to extract some standard details about our numerical features.\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hu22LwIzkU7j"
      },
      "outputs": [],
      "source": [
        "#The DataFrames object has a method called info(), that gives you more information about the data set.\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR-zxQhvlckd"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPNcp_WuldPd"
      },
      "outputs": [],
      "source": [
        "df.tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQb7q-pllBX9"
      },
      "source": [
        "###Filtering dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtvorQeelSsp"
      },
      "outputs": [],
      "source": [
        "# Selecting data by feature\n",
        "df[\"name\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTCz1-XmlhsD"
      },
      "outputs": [],
      "source": [
        "# Filtering\n",
        "df[df[\"sex\"]==\"female\"].head() # only the female data appear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWjLDk7El2ki"
      },
      "source": [
        "###Sorting\n",
        "We can also sort our features in ascending or descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuaPgBcBl6-o"
      },
      "outputs": [],
      "source": [
        "# Sorting\n",
        "df.sort_values(\"age\", ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb0F68yampMM"
      },
      "source": [
        "###Grouping\n",
        "We can also get statistics across our features for certain groups. Here we wan to see the average of our continuous features based on whether the passenger survived or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssYi8y_4mv89"
      },
      "outputs": [],
      "source": [
        "# Grouping\n",
        "survived_group = df.groupby(\"survived\")\n",
        "survived_group.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wos4WAR5ubTX"
      },
      "source": [
        "####Feature engineering\n",
        "We're now going to use feature engineering to create a column called family_size. We'll first define a function called get_family_size that will determine the family size using the number of parents and siblings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfkjE7Ilukux"
      },
      "outputs": [],
      "source": [
        "# Lambda expressions to create new features\n",
        "def get_family_size(sibsp, parch):\n",
        "    family_size = sibsp + parch\n",
        "    return family_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtpGJTxGunqP"
      },
      "outputs": [],
      "source": [
        "df[\"family_size\"] = df[[\"sibsp\", \"parch\"]].apply(lambda x: get_family_size(x[\"sibsp\"], x[\"parch\"]), axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJQOEyh8my7F"
      },
      "source": [
        "#Data Cleaning\n",
        "Data cleaning means fixing bad data in your data set.\n",
        "\n",
        "Bad data could be:\n",
        "\n",
        "- Empty cells\n",
        "- Data in wrong format\n",
        "- Wrong data\n",
        "- Duplicates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmcLVi_Pn5js"
      },
      "source": [
        "###Empty Cells\n",
        "Empty cells can potentially give you a wrong result when you analyze data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61BZEWMUnbVD"
      },
      "outputs": [],
      "source": [
        "# Remove Rows\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "new_df = df.dropna()\n",
        "\n",
        "print(new_df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHAV-MOmohTG"
      },
      "outputs": [],
      "source": [
        "#change the original DataFrame\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "print(df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bismm0-oper"
      },
      "outputs": [],
      "source": [
        "#Replace NULL values with the number 130:\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "df.fillna(130, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnDaF9SdowDp"
      },
      "outputs": [],
      "source": [
        "#Replace NULL values in the \"Calories\" columns with the number 130:\n",
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "df[\"Calories\"].fillna(130, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uBQbjWKo8Ml"
      },
      "outputs": [],
      "source": [
        "#Replace Using Mean, Median, or Mode\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "x = df[\"Calories\"].mean() #df[\"Calories\"].median(), df[\"Calories\"].mode()[0]\n",
        "\n",
        "df[\"Calories\"].fillna(x, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgOdMKuWuSYT"
      },
      "outputs": [],
      "source": [
        "# Dropping multiple columns\n",
        "df = df.drop([\"name\", \"cabin\", \"ticket\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmfRZsectw3h"
      },
      "outputs": [],
      "source": [
        "# Rows with at least one NaN value\n",
        "df[pd.isnull(df).any(axis=1)].head()\n",
        "# Drop rows with Nan values\n",
        "df = df.dropna() # removes rows with any NaN values\n",
        "df = df.reset_index() # reset's row indexes in case any rows were dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO9cFfEhqBsp"
      },
      "source": [
        "###Data of Wrong Format\n",
        "Cells with data of wrong format can make it difficult, or even impossible, to analyze data.\n",
        "\n",
        "To fix it, you have two options: remove the rows, or convert all cells in the columns into the same format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lHtrzmF6q2Ds"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Date'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/Documents/Sample_Projects/python_for_cs/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert Into a Correct Format\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../lab05/data/data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mto_string())\n",
            "File \u001b[0;32m~/Documents/Sample_Projects/python_for_cs/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/Documents/Sample_Projects/python_for_cs/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Date'"
          ]
        }
      ],
      "source": [
        "# Convert Into a Correct Format\n",
        "df = pd.read_csv('../../lab05/data/data.csv')\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "print(df.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yjrozqr-q8x7"
      },
      "outputs": [],
      "source": [
        "# Remove rows with a NULL value in the \"Date\" column:\n",
        "\n",
        "df.dropna(subset=['Date'], inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1T0NQWrwpA"
      },
      "source": [
        "####Fixing Wrong Data\n",
        "\"Wrong data\" does not have to be \"empty cells\" or \"wrong format\", it can just be wrong, it doesn't have to be wrong, but taking in consideration that this is the data set of someone's workout sessions, we conclude with the fact that this person did not work out in 450 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQZK9e7lsHDG"
      },
      "outputs": [],
      "source": [
        "#Replacing Values\n",
        "df.loc[7, 'Duration'] = 45"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsOuZK5ysXen"
      },
      "outputs": [],
      "source": [
        "# If the value is higher than 120, set it to 120:\n",
        "\n",
        "for x in df.index:\n",
        "  if df.loc[x, \"Duration\"] > 120:\n",
        "    df.loc[x, \"Duration\"] = 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoHsANFMsZ89"
      },
      "outputs": [],
      "source": [
        "# Removing Rows\n",
        "for x in df.index:\n",
        "  if df.loc[x, \"Duration\"] > 120:\n",
        "    df.drop(x, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5rUz7-IsjGZ"
      },
      "source": [
        "###Pandas - Removing Duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQZqm4uvswLo"
      },
      "outputs": [],
      "source": [
        "# Returns True for every row that is a duplicate, otherwise False:\n",
        "\n",
        "print(df.duplicated())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzmS_j1As0QD"
      },
      "outputs": [],
      "source": [
        "# Removing Duplicates\n",
        "# To remove duplicates, use the drop_duplicates() method.\n",
        "\n",
        "df.drop_duplicates(inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzipHFjTu3Qr"
      },
      "source": [
        "#Save data\n",
        "Finally, let's save our preprocessed data into a new CSV file to use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsPE6zBXu81d"
      },
      "outputs": [],
      "source": [
        "# Saving dataframe to CSV\n",
        "df.to_csv(\"cleaned_data.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
